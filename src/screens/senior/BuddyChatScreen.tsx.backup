import React, { useState, useEffect, useRef, useCallback } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  ScrollView,
  ActivityIndicator,
  Platform,
  Alert,
} from 'react-native';
import {
  chatWithBuddy,
  realtimeService,
} from '../../services/buddy';
import { speakBuddyMessage, stop as stopSpeaking } from '../../services/tts';
import {
  startListening,
  stopListening,
  cancelListening,
  requestMicrophonePermission,
  VoiceRecognitionResult,
} from '../../services/voice';
import { useCurrentUser } from '../../state/useCurrentUser';
import { SeniorColors } from '../../design/colors';
import BuddyAvatar from '../../components/BuddyAvatar';

/**
 * BuddyChatScreen (Senior)
 *
 * This screen provides a conversational interface between the senior and their AI buddy.
 * It now supports real-time voice interactions via the MCP server, with wake word detection.
 */
const BuddyChatScreen: React.FC = () => {
  const [messages, setMessages] = useState<{ role: 'user' | 'assistant'; content: string }[]>([
    { role: 'assistant', content: 'Hello! I’m your buddy. How can I help you today?' },
  ]);
  const [isBuddySpeaking, setIsBuddySpeaking] = useState(false);
  const [isWakeWordListening, setIsWakeWordListening] = useState(false); // Passive listening for wake word
  const [isVoiceSessionActive, setIsVoiceSessionActive] = useState(false); // Full real-time MCP session
  const [isProcessing, setIsProcessing] = useState(false); // For Buddy's thinking state
  const [currentSpokenText, setCurrentSpokenText] = useState(''); // Real-time transcription of user's speech
  const [emotion, setEmotion] = useState<'NEUTRAL' | 'HAPPY' | 'THINKING'>('NEUTRAL');
  
  const scrollViewRef = useRef<ScrollView>(null);
  const { user } = useCurrentUser();
  const seniorId = user?.role === 'senior' ? (user.activeSeniorId || user.uid) : null;
  const wakeWord = 'buddy'; // The wake word to activate the session

  // --- Initial Greeting & Component Lifecycle ---
  useEffect(() => {
    const speakIntro = async () => {
      setIsBuddySpeaking(true);
      setEmotion('HAPPY');
      await speakBuddyMessage('Hello! I’m your buddy. How can I help you today?');
      setIsBuddySpeaking(false);
      setEmotion('NEUTRAL');
      startWakeWordListener(); // Start wake word listening after intro
    };
    const timer = setTimeout(() => {
        speakIntro();
    }, 1000);

    return () => {
      clearTimeout(timer);
      // Ensure all listening and sessions are stopped on unmount
      cancelListening().catch(console.error);
      stopBuddyVoiceSession().catch(console.error);
    };
  }, []);

  // --- Callbacks for MCP Buddy Service ---
  const onTranscriptReceived = useCallback((transcript: string, isFinal: boolean) => {
    setCurrentSpokenText(transcript);
    if (isFinal) {
      console.log('Final user transcript (MCP session):', transcript);
      setMessages(prev => [...prev, { role: 'user', content: transcript }]);
      setCurrentSpokenText(''); // Clear current spoken text for next input
      setIsProcessing(true); // Buddy processes after user speaks
    }
  }, []);

  const onBuddySpeakingStarted = useCallback(() => {
    setIsBuddySpeaking(true);
    setEmotion('HAPPY'); // Buddy starts speaking
    setIsProcessing(false); // Stop thinking
  }, []);

  const onBuddySpeakingFinished = useCallback(() => {
    setIsBuddySpeaking(false);
    setEmotion('NEUTRAL'); // Buddy finished speaking
    // After Buddy speaks, we should go back to listening for the user
    // The mcpBuddyService should handle re-enabling its internal STT
  }, []);

  const onSessionEnded = useCallback(() => {
    console.log('Buddy voice session ended.');
    setIsVoiceSessionActive(false);
    setIsBuddySpeaking(false);
    setIsProcessing(false);
    setEmotion('NEUTRAL');
    setCurrentSpokenText('');
    setMessages(prev => [...prev, { role: 'assistant', content: "The voice session has ended." }]);
    startWakeWordListener(); // Go back to wake word listening
  }, []);

  const onSessionError = useCallback((error: Error) => {
    console.error('Buddy voice session error:', error);
    Alert.alert('Voice Error', `Something went wrong with the voice session: ${error.message}`);
    setIsVoiceSessionActive(false);
    setIsBuddySpeaking(false);
    setIsProcessing(false);
    setEmotion('NEUTRAL');
    setCurrentSpokenText('');
    setMessages(prev => [...prev, { role: 'assistant', content: "I'm having trouble with our voice conversation. Please try again." }]);
    startWakeWordListener(); // Go back to wake word listening
  }, []);

  // --- Wake Word Listener Logic ---
  const startWakeWordListener = useCallback(async () => {
    if (isVoiceSessionActive || isWakeWordListening) return; // Don't start if active or already listening

    const hasPermission = await requestMicrophonePermission();
    if (!hasPermission) {
      Alert.alert('Permission Denied', 'Microphone permission is required for voice interaction.');
      return;
    }

    console.log('Starting wake word listener...');
    setIsWakeWordListening(true);
    setCurrentSpokenText('Say "Buddy" to start the conversation...');

    await stopSpeaking(); // Stop any ongoing TTS

    try {
      await startListening({
        onPartialResults: (res: VoiceRecognitionResult) => {
          // Display partial results for wake word detection
          setCurrentSpokenText(res.transcript);
          const detectedWakeWord = res.transcript.toLowerCase().includes(wakeWord);
          if (detectedWakeWord && !isVoiceSessionActive && !isBuddySpeaking) {
            // Wake word detected, transition to active session
            console.log('Wake word detected!');
            stopListening(); // Stop current wake word listening
            setIsWakeWordListening(false);
            
            // Extract message after wake word
            const parts = res.transcript.toLowerCase().split(wakeWord);
            const initialMessage = parts[parts.length - 1].trim();
            
            startActiveVoiceSession(initialMessage);
          }
        },
        onFinalResult: (res: VoiceRecognitionResult) => {
          // If wake word was not detected in partial results, check final
          const detectedWakeWord = res.transcript.toLowerCase().includes(wakeWord);
          if (detectedWakeWord && !isVoiceSessionActive && !isBuddySpeaking) {
            console.log('Wake word detected (final result)!');
            setIsWakeWordListening(false);
            
            const parts = res.transcript.toLowerCase().split(wakeWord);
            const initialMessage = parts[parts.length - 1].trim();
            
            startActiveVoiceSession(initialMessage);
          } else {
            // No wake word, restart listening for it
            startWakeWordListener();
          }
        },
        onError: (error) => {
          console.error('Wake word listener error:', error);
          setIsWakeWordListening(false);
          setCurrentSpokenText('');
          // Attempt to restart or inform user
          Alert.alert('Listening Error', 'Failed to listen for wake word. Please try again.');
          // Consider a retry mechanism or a manual button to restart wake word listener
        },
      });
    } catch (error) {
      console.error('Failed to start wake word listener:', error);
      setIsWakeWordListening(false);
      setCurrentSpokenText('');
      Alert.alert('Microphone Error', 'Could not access microphone for wake word detection.');
    }
  }, [isVoiceSessionActive, isBuddySpeaking, isWakeWordListening, seniorId, onBuddySpeakingStarted, onBuddySpeakingFinished, onSessionEnded, onSessionError]);


  // --- Active Voice Session Management ---
  const startActiveVoiceSession = useCallback(async (initialMessage: string = '') => {
    if (!seniorId) {
      Alert.alert('Error', 'Senior ID not available. Cannot start voice session.');
      return;
    }
    if (isVoiceSessionActive) return;

    console.log('Starting active Buddy voice session...');
    setIsProcessing(true); // Indicate Buddy is 'thinking' while setting up session
    setIsVoiceSessionActive(true);
    setMessages(prev => [...prev, { role: 'assistant', content: "Voice session activated. How can I help?" }]);

    try {
      await startBuddyVoiceSession({
        onTranscriptReceived: onTranscriptReceived,
        onSpeakingStarted: onBuddySpeakingStarted,
        onSpeakingFinished: onBuddySpeakingFinished,
        onSessionEnded: onSessionEnded,
        onError: onSessionError,
      });

      setIsProcessing(false); // Session started, no longer 'thinking' about setup
      setEmotion('NEUTRAL'); // Initial state for new session

      if (initialMessage) {
        console.log('Sending initial message from wake word:', initialMessage);
        await sendBuddyVoiceMessage(initialMessage);
        setMessages(prev => [...prev, { role: 'user', content: initialMessage }]);
      }
    } catch (error) {
      console.error('Failed to start active Buddy voice session:', error);
      onSessionError(error as Error); // Use the general session error handler
    }
  }, [seniorId, onTranscriptReceived, onBuddySpeakingStarted, onBuddySpeakingFinished, onSessionEnded, onSessionError, isVoiceSessionActive]);


  const stopActiveVoiceSession = useCallback(async () => {
    if (!isVoiceSessionActive) return;

    console.log('Stopping active Buddy voice session...');
    try {
      await stopBuddyVoiceSession();
      // State will be updated by onSessionEnded callback
    } catch (error) {
      console.error('Failed to stop active Buddy voice session:', error);
      Alert.alert('Error', 'Failed to stop voice session.');
    }
  }, [isVoiceSessionActive, stopBuddyVoiceSession]);


  // --- Manual Text Sending (Fallback/Alternative) ---
  const handleManualSend = async (text: string) => {
    if (!seniorId || !text.trim()) return;

    // For now, manual send always uses text chat via Firebase function
    // Could be extended to send to active voice session if desired
    setMessages(prev => [...prev, { role: 'user', content: text }]);
    setIsBuddySpeaking(true);
    setIsProcessing(true);
    setEmotion('THINKING');
    try {
      const response = await sendBuddyTextMessage(seniorId, text, 'manual');
      setMessages(prev => [...prev, { role: 'assistant', content: response }]);
      setEmotion('HAPPY');
      await speakBuddyMessage(response, 1.0, () => {
        setIsBuddySpeaking(false);
        setEmotion('NEUTRAL');
      });
    } catch (e) {
      console.warn('Text chat error', e);
      setMessages(prev => [...prev, { role: 'assistant', content: "I'm having trouble connecting right now. Please try again later." }]);
      await speakBuddyMessage("I'm having trouble connecting right now. Please try again later.", 1.0, () => {
        setIsBuddySpeaking(false);
        setEmotion('NEUTRAL');
      });
    } finally {
      setIsProcessing(false);
    }
  };

  // Auto-scroll to bottom
  useEffect(() => {
    if (scrollViewRef.current) {
        scrollViewRef.current.scrollToEnd({ animated: true });
    }
  }, [messages, currentSpokenText]);

  if (!user) {
     return <View style={[styles.container, styles.center]}><ActivityIndicator size="large" /></View>;
  }

  const micButtonText = isVoiceSessionActive
    ? 'End Voice Chat'
    : (isWakeWordListening ? 'Listening for "Buddy"...' : 'Start Listening for "Buddy"');

  return (
    <View style={styles.container}>
      {/* Avatar Section */}
      <View style={styles.avatarContainer}>
        <BuddyAvatar 
            emotion={emotion} 
            isSpeaking={isBuddySpeaking} 
            isProcessing={isProcessing}
            size={200} 
        />
        {(isVoiceSessionActive || isWakeWordListening) && currentSpokenText.length > 0 && (
          <View style={styles.currentSpokenTextContainer}>
            <Text style={styles.currentSpokenText}>{currentSpokenText}</Text>
          </View>
        )}
      </View>

      <ScrollView
        ref={scrollViewRef}
        style={styles.messageContainer}
        contentContainerStyle={{ paddingVertical: 16 }}
      >
        {messages.map((msg, idx) => (
          <View
            key={idx}
            style={msg.role === 'user' ? styles.userBubble : styles.buddyBubble}
          >
            <Text style={msg.role === 'user' ? styles.userText : styles.buddyText}>
              {msg.content}
            </Text>
          </View>
        ))}
      </ScrollView>
      <View style={styles.controls}>
        <TouchableOpacity
          style={isVoiceSessionActive ? styles.listeningButton : styles.microphoneButton}
          onPress={isVoiceSessionActive ? stopActiveVoiceSession : startWakeWordListener}
          disabled={isBuddySpeaking}
        >
          <Text style={styles.buttonText}>{micButtonText}</Text>
        </TouchableOpacity>
        {/* Potentially add a text input here for manual entry, using handleManualSend */}
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#fff',
  },
  center: {
    justifyContent: 'center',
    alignItems: 'center',
  },
  avatarContainer: {
    alignItems: 'center',
    paddingTop: 40,
    paddingBottom: 20,
    backgroundColor: '#FFF9C4', // Match avatar bg slightly
  },
  currentSpokenTextContainer: {
    backgroundColor: 'rgba(0,0,0,0.7)',
    borderRadius: 20,
    paddingHorizontal: 15,
    paddingVertical: 10,
    marginTop: 10,
    position: 'absolute',
    bottom: 5, // Position below the avatar
  },
  currentSpokenText: {
    color: '#fff',
    fontSize: 16,
    textAlign: 'center',
  },
  messageContainer: {
    flex: 1,
    paddingHorizontal: 16,
  },
  userBubble: {
    alignSelf: 'flex-end',
    backgroundColor: SeniorColors.primary.blue,
    padding: 12,
    borderRadius: 16,
    marginBottom: 8,
    maxWidth: '80%',
  },
  buddyBubble: {
    alignSelf: 'flex-start',
    backgroundColor: SeniorColors.gray[200],
    padding: 12,
    borderRadius: 16,
    marginBottom: 8,
    maxWidth: '80%',
  },
  userText: {
    color: '#fff',
    fontSize: 18,
  },
  buddyText: {
    color: '#1a202c',
    fontSize: 18,
  },
  controls: {
    flexDirection: 'row',
    justifyContent: 'center',
    padding: 16,
    borderTopWidth: 1,
    borderColor: '#edf2f7',
    paddingBottom: 30,
  },
  microphoneButton: {
    backgroundColor: SeniorColors.primary.blue,
    paddingHorizontal: 32,
    paddingVertical: 16,
    borderRadius: 30,
  },
  listeningButton: {
    backgroundColor: SeniorColors.error.primary,
    paddingHorizontal: 32,
    paddingVertical: 16,
    borderRadius: 30,
  },
  buttonText: {
    color: '#fff',
    fontWeight: '600',
    fontSize: 18,
  },
});

export default BuddyChatScreen;